{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Numeros y letras escritos a mano - Exportaci√≥n",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "in3OdvpUG_9_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FDu5Fcgefbc"
      },
      "source": [
        "#Descargar set de datos de MNIST (Numeros escritos a mano, etiquetados)\n",
        "datos, metadatos = tfds.load('emnist', as_supervised=True, with_info=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA7HIIXZefLM"
      },
      "source": [
        "#Obtenemos en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
        "datos_entrenamiento, datos_pruebas = datos['train'], datos['test']\n",
        "\n",
        "#Etiquetas de las 10 categorias posibles (simplemente son los numeros del 0 al 9)\n",
        "nombres_clases = metadatos.features['label'].names"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ofrDIuBlC-0",
        "outputId": "d0f2998e-31de-4c4f-8fe2-54ca7a515d60"
      },
      "source": [
        "metadatos"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='emnist',\n",
              "    version=3.0.0,\n",
              "    description='The EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19 and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset.\n",
              "\n",
              "Note: Like the original EMNIST data, images provided here are inverted horizontally and rotated 90 anti-clockwise. You can use `tf.transpose` within `ds.map` to convert the images to a human-friendlier format.',\n",
              "    homepage='https://www.nist.gov/itl/products-and-services/emnist-dataset',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=62),\n",
              "    }),\n",
              "    total_num_examples=814255,\n",
              "    splits={\n",
              "        'test': 116323,\n",
              "        'train': 697932,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{cohen_afshar_tapson_schaik_2017,\n",
              "        title={EMNIST: Extending MNIST to handwritten letters},\n",
              "        DOI={10.1109/ijcnn.2017.7966217},\n",
              "        journal={2017 International Joint Conference on Neural Networks (IJCNN)},\n",
              "        author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},\n",
              "        year={2017}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JwUp_ATefIu"
      },
      "source": [
        "#Funcion de normalizacion para los datos (Pasar valor de los pixeles de 0-255 a 0-1)\n",
        "#Hace que la red aprenda mejor y mas rapido\n",
        "def normalizar(imagenes, etiquetas):\n",
        "  imagenes = tf.cast(imagenes, tf.float32)\n",
        "  #imagenes = tf.transpose(imagenes)\n",
        "  imagenes /= 255 #Aqui lo pasa de 0-255 a 0-1\n",
        "  return imagenes, etiquetas\n",
        "\n",
        "#Normalizar los datos de entrenamiento y pruebas con la funcion que hicimos\n",
        "datos_entrenamiento = datos_entrenamiento.map(normalizar)\n",
        "datos_pruebas = datos_pruebas.map(normalizar)\n",
        "\n",
        "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
        "datos_entrenamiento = datos_entrenamiento.cache()\n",
        "datos_pruebas = datos_pruebas.cache()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9lqdbdFefGO"
      },
      "source": [
        "#Crear el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    #tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.Dense(62, activation=tf.nn.softmax) #Para redes de clasificacion\n",
        "])\n",
        "\n",
        "#Compilar el modelo\n",
        "modelo.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLu6QxrMefD3",
        "outputId": "d0cc0909-86b5-4c56-f6d2-d5d1df2d4130"
      },
      "source": [
        "#Los numeros de datos en entrenamiento y pruebas (60k y 10k)\n",
        "num_ej_entrenamiento = metadatos.splits[\"train\"].num_examples\n",
        "num_ej_pruebas = metadatos.splits[\"test\"].num_examples\n",
        "\n",
        "#El trabajo por lotes permite que entrenamientos con gran cantidad de datos se haga de manera mas eficiente\n",
        "TAMANO_LOTE = 128\n",
        "\n",
        "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria para que la red\n",
        "#no se vaya a aprender el orden de las cosas\n",
        "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)\n",
        "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)\n",
        "print(num_ej_entrenamiento/TAMANO_LOTE)\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "#Entrenar\n",
        "historial = modelo.fit((datos_entrenamiento),\n",
        "                       epochs=20,\n",
        "                       steps_per_epoch= math.ceil(num_ej_entrenamiento/TAMANO_LOTE))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5452.59375\n",
            "Epoch 1/20\n",
            "5453/5453 [==============================] - 184s 11ms/step - loss: 0.7969 - accuracy: 0.7441\n",
            "Epoch 2/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.5726 - accuracy: 0.8044\n",
            "Epoch 3/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.5322 - accuracy: 0.8167\n",
            "Epoch 4/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.5147 - accuracy: 0.8211\n",
            "Epoch 5/20\n",
            "5453/5453 [==============================] - 59s 11ms/step - loss: 0.5021 - accuracy: 0.8255\n",
            "Epoch 6/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4953 - accuracy: 0.8266\n",
            "Epoch 7/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4877 - accuracy: 0.8288\n",
            "Epoch 8/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4855 - accuracy: 0.8304\n",
            "Epoch 9/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4805 - accuracy: 0.8320\n",
            "Epoch 10/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4791 - accuracy: 0.8321\n",
            "Epoch 11/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4733 - accuracy: 0.8335\n",
            "Epoch 12/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4744 - accuracy: 0.8330\n",
            "Epoch 13/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4724 - accuracy: 0.8346\n",
            "Epoch 14/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4701 - accuracy: 0.8351\n",
            "Epoch 15/20\n",
            "5453/5453 [==============================] - 60s 11ms/step - loss: 0.4691 - accuracy: 0.8351\n",
            "Epoch 16/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4665 - accuracy: 0.8353\n",
            "Epoch 17/20\n",
            "5453/5453 [==============================] - 62s 11ms/step - loss: 0.4651 - accuracy: 0.8360\n",
            "Epoch 18/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4652 - accuracy: 0.8363\n",
            "Epoch 19/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4657 - accuracy: 0.8361\n",
            "Epoch 20/20\n",
            "5453/5453 [==============================] - 61s 11ms/step - loss: 0.4640 - accuracy: 0.8365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_ltzdMAYHT4",
        "outputId": "858052a2-f6e5-43e1-9631-106536b788bf"
      },
      "source": [
        "modelo"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f9ffa0ae110>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbdk5KrZKxqB"
      },
      "source": [
        "#Exportar el modelo en formato h5\n",
        "modelo.save('numerosyletras.h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8knzLt6MKxlI"
      },
      "source": [
        "#El equipo es Linux. Listemos el contenido de la carpeta actual para ver que se exporto el modelo\n",
        "#!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GSVhBrkKxda"
      },
      "source": [
        "#Para convertirlo a tensorflow.js, primero debemos instalar la libreria\n",
        "#!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnMzWaOJMBZH"
      },
      "source": [
        "#Crear carpeta donde se colocaran los archivos resultantes\n",
        "#!mkdir carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XfIiEPdMBW7"
      },
      "source": [
        "#Realizar la exportacion a la carpeta de salida\n",
        "#!tensorflowjs_converter --input_format keras numeros.h5 carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsgARXD9MBUU"
      },
      "source": [
        "#Confirmar que en la carpeta de salida se hayan generado los archivos. Deben aparecer archivos \"bin\" y \"json\"\n",
        "#!ls carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKrTs6CRMBR-"
      },
      "source": [
        "#Para descargarlos, da clic del lado izquierdo en el icono de la carpeta\n",
        "#y expande carpeta_salida. En los archivos utiliza los 3 puntos para descargarlos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGuC0utZij5L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "5wX1EHK-6Uyp",
        "outputId": "ec035694-e897-420a-c44f-d80da9bf88ab"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "img = cv2.imread('tuDibujo.png', 0)\n",
        "cv2_imshow(img)\n",
        "resized = cv2.resize(img, (28,28))\n",
        "img_np = np.array(resized, dtype=np.float32)\n",
        "img_np = np.reshape(img_np, (-1, 28, 28, 1))\n",
        "img_np /= 255\n",
        "img_np = np.absolute(img_np - 1)\n",
        "img_np = img_np.T\n",
        "cv2_imshow(resized)\n",
        "print(img_np.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAEJUlEQVR4nO2dMU8UURDH/2f8AEthzZUmmOyZmFCyJBKIkQRDAd1taQfaWHrEL3Cl3T46sYFYYcWaaGfCu8TEYDQehfXtN8CCRCMg3M3MZf+5m199M29++3bevd3bhcYZJoNbdRdghYuw4SJsuAgbLsKGi7DhImy4CBsuwoaLsOEibLgIGy7ChotcIj570riWTjQb6yrOTCjyYcbq2Ax2JQ2Lm9hh7xBYaOWt6zV2cGeu1WylicGQl9Efi2IFWC6G+ODxi/Mh7611j/XDXkA9I2Gnj+XNfLgPVzH24/dfANZX28qBL6I7DoMcmC1GDPpZtFOgGXRDX0Ahcn4g0kIUXMwC6faxfPRL1ShCAWB/IA0vVgHMm7koeqSBswY0LRZDrwS2Ookix99qVCLq4WM4PGkdJeo8tYsAVdbbeJ3o89S+10rKjb3FSp+n9hkBqqw3t9RuKbMQiKAqnuu/IRlEgBg+f0K7myhScIgACN2eavmiEUGVqUxqX7X+kJRpfFqJw3lEkJQbe6U4mufUAlDNyFNSiWhSEp1aOlxkLLQRpKFcIhlKaShXsytycs2IAhdhw0XYcBE2XIQNF2HDRdhwETZchA0ukYgFaSiXSImmNJRNJJOGcol8mRCR8GO9KY2lEnmDx+JYJpHwfjkXBzOJdLApDyYSCaezuTyaR6TqoqMIpxGpFnvtXBFPI1LEtKuJZ7kbH+/PfUw0CVhmJOBhokpAIlIdItdl4BAJ6ydbLWUO+VOEVk9xnw1y4NVAmeS2wfFUUi3GdDvXZqlbpL8bD5CWiTpRvSIHuwcA9rNEn6pGkbjbOwLaeWaSrTaRsP8OWHqUJ0b5ahIJO32k2Q3vaYyGfMGTxxZNwasBN1CDSLFir2EgMtxLSf8y1GszI6LqkfAhCKLaWa4Z9D+otvHAuMoaHdWMsEgAPBdWaji28Qa4CBsuwoaLsOEibLgIGy6CPlLDOtTIRRRPKYwDuUhEy64MPZoZyezK0CO/sOK6rpLPSMnV6xqRzLAMPWIRsl6Xi3ybkBmJX+eblnWokYqUuGtahxqpyAHWLMvQI/weqWYwSGwrUSKckRILiWkdaoQidGeWVKRPtviKe4RsowW/QuTDRdhwETZchA0XYcNF2HARNqZcpLItwgKZyFu8NK5DjegKUf2yxxgQzUiJB4lxHWqEIplxGXpEInz3UIQ9wncPZcq/RxR/B2B8SETIfmE/RyaSWZehRyLCuGiJVi3GRWuqV60A6/+4YYFAhLLXJT1C2SKCGansi7BgZJFqZhxl6BlZJI6hCAumV6Q/hiIsmOoZIdzEC0ROwbiJl+21MusiLJgYkZG3KA1Q7lCmehvPuIkXiWTmRVgg6BHKFtG8dMzFNDc7Jy7Chouw4SJsuAgbLsKGi7DhImy4CBsuwoaLsDExIr8B7wIuGlRCE2YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F9FF039C5D0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAX0lEQVR4nGP8z4AbMOGRo4pkGwMDAwPDU2MkSUZMB4m+xiPJ8J8Rj50wOdp7BQFe4pZ8sFEczv4PBTOh/N//EQCbP6no2j/4JD+RbCzMtXzYtMJ0JuHTiRXQMcqIkwQAjZAkLMXM3ukAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9FF039C550>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmLTE67duspv"
      },
      "source": [
        "model = load_model('numerosyletras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYXryH2xi0M4",
        "outputId": "9b4791d0-6d61-40ba-c79c-893fdc6ba63a"
      },
      "source": [
        "pred_probab = modelo.predict(img_np)[0]\n",
        "pred_class = list(pred_probab).index(max(pred_probab))\n",
        "print(nombres_clases[pred_class])\n",
        "print(pred_class)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9t6UzhCjafJ"
      },
      "source": [
        "import string\n",
        "new_labels = list(range(10))+list(string.ascii_uppercase)+list(string.ascii_lowercase)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18RsXtcj79s",
        "outputId": "d436bea1-40d1-405d-ca97-9931a9ad9d0f"
      },
      "source": [
        "len(new_labels)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0rahfW1kDE3",
        "outputId": "b6a1c62f-cfa2-40e4-f641-018cd0720faf"
      },
      "source": [
        "len(new_labels)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ete_XqejsT8y",
        "outputId": "900b7ff9-1e3d-4c25-e325-cabb1d7644b9"
      },
      "source": [
        "new_labels[pred_class]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'j'"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaVJ4Dxzscc-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}